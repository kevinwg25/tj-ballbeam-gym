(ctrl shift g is shortcut to go to source control on vscode)

PPO from: https://github.com/nikhilbarhate99/PPO-PyTorch/
Ballbeam from: https://github.com/simon-larsson/ballbeam-gym

get reward function working
angular velocity is set irl, not in code. does not model how an actual servo worksvelocity exceeds max_v??

rem to do: reward function import file, have default reward function (functionality)

<<<<<<< HEAD
=======
acceleration shown in simulation is not quite what is expected irl,
 - 9.8sin(0.2) = 1.95 but we have 1.39


high priority:
lower margin of error, currently it is too high
 - ball is 5 cm away from setpoint, but "accuracy" is still >0.9
fix signing of the reward components
 - aa and v
instead of exp function to increase penalty, use velocity?
 - exp is arbitrary and should still work fine, but velocity sounds more practical and robust?


low priority:
as simulation runs, have another window showing the graph of reward
 - figure out what happens when moves to another episode
>>>>>>> dc4e549529f3775a2f3631660e3d2dcf83533917

notes:
- motor physical limitation
    - in update() of ballbeam.py, OA made note that "simulation could be improved further by using voltage as input and a motor simulation deciding theta"
    - insead of angular acceleration, more accurate to use torque
    - talk to dean about stepper motor from robolab (its a rotary encoder used in 3d printers, very good)
- make random initial velocity initialization robust (temporarily just a random number between 0,1 but this will change depending on unit conversion)
    - in base.py, since bb = BallBeam object hasn't yet been created, the random initial_velocity range is different from reset() when initializing. not a big problem, but it is something that culd be fixed
- maybe test around with max_ep_len for training, as it is currently 10x less than in testing. choose it to be a reasonable value for what we decide is the maximum waiting time for ball to balance
